{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtención e Inserción de datos del histórico de AWS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizado por: Luis Mendoza Montero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Desarrollo del trabajo: **\n",
    "\n",
    "- Seleccionar el tipo de familia y la región\n",
    "- Obtener histórico de datos desde la nube para la instancia **.2xlarge**\n",
    "- Insertar datos originales a nuestra BBDD\n",
    "\n",
    "** Regiones y zonas disponibles para cada tipo de familia **\n",
    "\n",
    "* C4:\n",
    "   - ap-northeast-1\n",
    "   - ap-northeast-2\n",
    "   - ap-south-1\n",
    "   - ap-southeast-1\n",
    "   - ap-southeast-2\n",
    "   - ca-central-1\n",
    "   - eu-central-1\n",
    "   - eu-west-1\n",
    "   - eu-west-2\n",
    "   - sa-east-1\n",
    "   - us-east-1\n",
    "   - us-east-2\n",
    "   - us-west-1\n",
    "   - us-west-2\n",
    "   \n",
    "* C5:\n",
    "   - ap-northeast-2\n",
    "   - ap-south-1\n",
    "   - ap-southeast-1\n",
    "   - ap-southeast-2\n",
    "   - ca-central-1\n",
    "   - eu-central-1\n",
    "   - eu-west-1\n",
    "   - eu-west-2\n",
    "   - sa-east-1\n",
    "   - us-east-1\n",
    "   - us-east-2\n",
    "   - us-west-1\n",
    "   - us-west-2\n",
    "   \n",
    "* D2:\n",
    "   - ap-northeast-1\n",
    "   - ap-northeast-2\n",
    "   - ap-south-1\n",
    "   - ap-southeast-1\n",
    "   - ap-southeast-2\n",
    "   - ca-central-1\n",
    "   - eu-central-1\n",
    "   - us-east-1\n",
    "   - us-east-2\n",
    "   - us-west-1\n",
    "   - us-west-2\n",
    "   \n",
    "* F1:\n",
    "   - eu-west-1\n",
    "   - us-east-1\n",
    "   - us-west-2\n",
    "   \n",
    "* H1:\n",
    "   - eu-west-1\n",
    "   - us-east-1\n",
    "   - us-east-2\n",
    "   - us-west-2\n",
    "   \n",
    "* I3:\n",
    "   - ap-northeast-1\n",
    "   - ap-northeast-2\n",
    "   - ap-south-1\n",
    "   - ap-southeast-1\n",
    "   - ap-southeast-2\n",
    "   - ca-central-1\n",
    "   - eu-central-1\n",
    "   - eu-west-1\n",
    "   - eu-west-2\n",
    "   - sa-east-1\n",
    "   - us-east-1\n",
    "   - us-east-2\n",
    "   - us-west-1\n",
    "   - us-west-2\n",
    "   \n",
    "* M4:\n",
    "   - ap-northeast-1\n",
    "   - ap-northeast-2\n",
    "   - ap-south-1\n",
    "   - ap-southeast-1\n",
    "   - ap-southeast-2\n",
    "   - ca-central-1\n",
    "   - eu-central-1\n",
    "   - eu-west-1\n",
    "   - eu-west-2\n",
    "   - sa-east-1\n",
    "   - us-east-2\n",
    "   - eu-west-1\n",
    "   - eu-west-2\n",
    "   \n",
    "* M5:\n",
    "   - ap-northeast-2\n",
    "   - ap-south-1\n",
    "   - ap-southeast-1\n",
    "   - ap-southeast-2\n",
    "   - ca-central-1\n",
    "   - eu-central-1\n",
    "   - eu-west-1\n",
    "   - eu-west-2\n",
    "   - us-east-1\n",
    "   - us-east-2\n",
    "   - us-west-1\n",
    "   - us-west-2\n",
    "   \n",
    "* P3:\n",
    "   - ap-northeast-1\n",
    "   - ap-northeast-2\n",
    "   - eu-west-1\n",
    "   - us-east-1\n",
    "   - us-east-2\n",
    "   - us-west-2\n",
    " \n",
    "* R4:\n",
    "   - ap-northeast-1\n",
    "   - ap-northeast-2\n",
    "   - ap-south-1\n",
    "   - ap-southeast-1\n",
    "   - ca-central-1\n",
    "   - eu-central-1\n",
    "   - eu-west-1\n",
    "   - eu-west-2\n",
    "   - sa-east-1\n",
    "   - us-east-1\n",
    "   - us-east-2\n",
    "   - us-west-1\n",
    "   - us-west-2\n",
    "   \n",
    "* T2:\n",
    "   - ap-northeast-1\n",
    "   - ap-northeast-2\n",
    "   - ap-south-1\n",
    "   - ap-southeast-1\n",
    "   - ap-southeast-2\n",
    "   - ca-central-1\n",
    "   - eu-central-1\n",
    "   - eu-west-1\n",
    "   - sa-east-1\n",
    "   - us-east-1\n",
    "   - us-east-2\n",
    "   - us-west-1\n",
    "   - us-west-2\n",
    "   \n",
    "* X1e:\n",
    "   - ap-northeast-1\n",
    "   - eu-west-1\n",
    "   - us-east-1\n",
    "   - us-west-2\n",
    "\n",
    "\n",
    "** NO TODAS LAS REGIONES ESTÁ DISPONIBLES PARA CADA FAMILIA **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Especificar Tamaño de instancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "instancia = '2xlarge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Especificar Familia de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "family = 'X1e'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Especificar Región"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "region = 'us-west-2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**----------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sacamos las fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descarga del histórico desde 2018-07-06T22:22:47 hasta 2018-10-04T22:22:47\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, date, time, timedelta\n",
    "import calendar\n",
    "\n",
    "# Fecha de comienzo (90 días anteriores)\n",
    "date = \"%Y-%m-%dT%H:%M:%S\"\n",
    "today = datetime.now() # Fecha actual\n",
    "ndays = timedelta(days=90) \n",
    "start = today-ndays # Se restan 90 días a la fecha actual\n",
    "start = start.strftime(date) \n",
    "\n",
    "# Fecha de finalización (Actual)\n",
    "end = today.strftime(date) \n",
    "fam = family.lower()\n",
    "instance_types  = [fam + '.' + instancia]\n",
    "\n",
    "number_of_days = 90\n",
    "print (\"Descarga del histórico desde \" + start + \" hasta \" + end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import boto as boto\n",
    "import boto.ec2 as ec2\n",
    "import datetime, time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use\n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "ec2 = boto.ec2.connect_to_region(region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Procesando instancia: x1e.2xlarge ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Procesamos la salida y lo convertimos en un dataframe\n",
    "#\n",
    "\n",
    "l = []\n",
    "for instance in instance_types:\n",
    "    sys.stdout.write(\"*** Procesando instancia: \" + instance + \" ***\\n\")\n",
    "    sys.stdout.flush()\n",
    "    prices = ec2.get_spot_price_history(start_time=start, end_time=end, instance_type=instance)\n",
    "    for price in prices:\n",
    "        d = {'InstanceType': price.instance_type, \n",
    "             'AvailabilityZone': price.availability_zone, \n",
    "             'SpotPrice': price.price, \n",
    "             'Timestamp': price.timestamp,\n",
    "             'Description': price.product_description}\n",
    "        l.append(d)\n",
    "    next = prices.next_token\n",
    "    while (next != ''):\n",
    "        sys.stdout.write(\".\")\n",
    "        sys.stdout.flush()\n",
    "        prices = ec2.get_spot_price_history(start_time=start, end_time=end, instance_type=instance,\n",
    "                                            next_token=next )\n",
    "        for price in prices:\n",
    "            d = {'InstanceType': price.instance_type, \n",
    "                 'AvailabilityZone': price.availability_zone, \n",
    "                 'SpotPrice': price.price, \n",
    "                 'Timestamp': price.timestamp,\n",
    "                 'Description': price.product_description}\n",
    "            l.append(d)\n",
    "        next = prices.next_token\n",
    "        \n",
    "    sys.stdout.write(\"\\n\")\n",
    "\n",
    "df = pd.DataFrame(l)\n",
    "df = df.set_index(pd.to_datetime(df['Timestamp']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertimos los datos a un dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convertimos de formato df a csv para guardar la BBDD\n",
    "df.to_csv('datos.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insertar en la Base de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos descargados e insertados con éxito\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "\n",
    "# Abrimos el archivo CSV\n",
    "f=open('datos.csv','r') \n",
    "reader = csv.reader(f, delimiter=',')\n",
    "\n",
    "# Creamos la variable con el nombre de la tabla (categoría + región)\n",
    "indice = 0\n",
    "lista = []\n",
    "while indice < len(region):\n",
    "    carac = region[indice]\n",
    "    if carac == '-':\n",
    "        carac = '_'\n",
    "    lista.append(carac)\n",
    "    indice += 1\n",
    "cadena = \" \".join(lista)\n",
    "reg = (cadena.replace(' ', ''))\n",
    "\n",
    "table = family+\"_\"+reg\n",
    "# Conectar con la base de datos, si no existe la crea automáticamente\n",
    "conexion = sqlite3.connect(\"BBDD.db\")\n",
    "\n",
    "# Para poder ejecutar código SQL, tenemos que crear un cursor primero, el nombre de la tabla será la familia de las categorías\n",
    "cursor = conexion.cursor()\n",
    "cursor.execute(\"CREATE TABLE IF NOT EXISTS \" + table + \" (AvailabilityZone VARCHAR(100), Description VARCHAR(100), InstanceType VARCHAR(100), SpotPrice INTEGER, Timestamp Datetime, PRIMARY KEY('AvailabilityZone','InstanceType','Timestamp','SpotPrice','Description'))\")\n",
    "\n",
    "# Llenamos la BD con los datos del CSV\n",
    "for row in reader:\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO \" + table + \" VALUES (?, ?, ?, ?, ?)\", (row[0], row[1], row[2], row[3], row[4]))\n",
    "    conexion.commit()\n",
    "\n",
    "# Guardamos los cambios haciendo un commit\n",
    "conexion.commit()\n",
    "\n",
    "# Cerrar la conexión siempre\n",
    "conexion.close()\n",
    "\n",
    "print(\"Datos descargados e insertados con éxito\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
